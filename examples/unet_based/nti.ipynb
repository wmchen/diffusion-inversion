{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lpips\n",
    "import torch\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from diffusers.training_utils import free_memory\n",
    "from accelerate.utils import set_seed\n",
    "\n",
    "from inversions.unet_based.nti import SDInversionPipeline, SDXLInversionPipeline, CustomDDIMInversionScheduler, image2latents, latents2image\n",
    "from inversions.utils import pil2tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(666)\n",
    "\n",
    "torch_dtype = torch.float16\n",
    "variant = \"fp16\"\n",
    "device = \"cuda\"\n",
    "num_inference_steps = 50\n",
    "lpips_loss = lpips.LPIPS(net='alex')\n",
    "\n",
    "image_path = \"../../demo/alley.jpg\"\n",
    "prompt = \"A narrow alley way with a building in the background.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Diffusion v1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"/home/ailab/model_weights/stable-diffusion/stable-diffusion-v1-5/\"\n",
    "scheduler = CustomDDIMInversionScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
    "pipe = SDInversionPipeline.from_pretrained(model_id, torch_dtype=torch_dtype, variant=variant, scheduler=scheduler)\n",
    "pipe.to(device)\n",
    "\n",
    "inv_result = pipe.inverse(\n",
    "    image=image_path,\n",
    "    prompt=prompt,\n",
    "    guidance_scale=7.5,\n",
    "    num_inference_steps=num_inference_steps\n",
    ")\n",
    "\n",
    "ori_image = inv_result.ori_image\n",
    "vae_latent = image2latents(pipe, ori_image)\n",
    "vae_recon = latents2image(pipe, vae_latent)\n",
    "\n",
    "recon_image = pipe(\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    guidance_scale=7.5,\n",
    "    uncond_embeds=inv_result.uncond_embeds,\n",
    "    latents=inv_result.zT\n",
    ").images[0]\n",
    "\n",
    "del inv_result, pipe\n",
    "free_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_psnr = psnr(np.array(ori_image), np.array(vae_recon))\n",
    "vae_ssim = ssim(np.array(ori_image), np.array(vae_recon), win_size=11, channel_axis=2)\n",
    "vae_lpips = lpips_loss(pil2tensor(ori_image), pil2tensor(vae_recon)).item()\n",
    "print(f\"[VAE Reconstruction] PSNR: {vae_psnr:.2f}, SSIM: {vae_ssim:.4f}, LPIPS: {vae_lpips:.4f}\")\n",
    "\n",
    "psnr_score = psnr(np.array(ori_image), np.array(recon_image))\n",
    "ssim_score = ssim(np.array(ori_image), np.array(recon_image), win_size=11, channel_axis=2)\n",
    "lpips_score = lpips_loss(pil2tensor(ori_image), pil2tensor(recon_image)).item()\n",
    "print(f\"[NTI] PSNR: {psnr_score:.2f}, SSIM: {ssim_score:.4f}, LPIPS: {lpips_score:.4f}\")\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "axs = fig.subplots(1, 3)\n",
    "axs[0].set_title(\"Origin\")\n",
    "axs[0].imshow(np.array(ori_image))\n",
    "axs[1].set_title(\"VAE Recon.\")\n",
    "axs[1].imshow(np.array(vae_recon))\n",
    "axs[2].set_title(\"NTI\")\n",
    "axs[2].imshow(np.array(recon_image))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Diffusion v2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"/home/ailab/model_weights/stable-diffusion/stable-diffusion-v2-1/\"\n",
    "scheduler = CustomDDIMInversionScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
    "pipe = SDInversionPipeline.from_pretrained(model_id, torch_dtype=torch_dtype, variant=variant, scheduler=scheduler)\n",
    "pipe.to(device)\n",
    "\n",
    "inv_result = pipe.inverse(\n",
    "    image=image_path,\n",
    "    prompt=prompt,\n",
    "    guidance_scale=7.5,\n",
    "    num_inference_steps=num_inference_steps\n",
    ")\n",
    "\n",
    "ori_image = inv_result.ori_image\n",
    "vae_latent = image2latents(pipe, ori_image)\n",
    "vae_recon = latents2image(pipe, vae_latent)\n",
    "\n",
    "recon_image = pipe(\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    guidance_scale=7.5,\n",
    "    uncond_embeds=inv_result.uncond_embeds,\n",
    "    latents=inv_result.zT\n",
    ").images[0]\n",
    "\n",
    "del inv_result, pipe\n",
    "free_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_psnr = psnr(np.array(ori_image), np.array(vae_recon))\n",
    "vae_ssim = ssim(np.array(ori_image), np.array(vae_recon), win_size=11, channel_axis=2)\n",
    "vae_lpips = lpips_loss(pil2tensor(ori_image), pil2tensor(vae_recon)).item()\n",
    "print(f\"[VAE Reconstruction] PSNR: {vae_psnr:.2f}, SSIM: {vae_ssim:.4f}, LPIPS: {vae_lpips:.4f}\")\n",
    "\n",
    "psnr_score = psnr(np.array(ori_image), np.array(recon_image))\n",
    "ssim_score = ssim(np.array(ori_image), np.array(recon_image), win_size=11, channel_axis=2)\n",
    "lpips_score = lpips_loss(pil2tensor(ori_image), pil2tensor(recon_image)).item()\n",
    "print(f\"[NTI] PSNR: {psnr_score:.2f}, SSIM: {ssim_score:.4f}, LPIPS: {lpips_score:.4f}\")\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "axs = fig.subplots(1, 3)\n",
    "axs[0].set_title(\"Origin\")\n",
    "axs[0].imshow(np.array(ori_image))\n",
    "axs[1].set_title(\"VAE Recon.\")\n",
    "axs[1].imshow(np.array(vae_recon))\n",
    "axs[2].set_title(\"NTI\")\n",
    "axs[2].imshow(np.array(recon_image))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDXL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"/home/ailab/model_weights/stable-diffusion/sdxl-base-v1.0/\"\n",
    "scheduler = CustomDDIMInversionScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
    "pipe = SDXLInversionPipeline.from_pretrained(model_id, torch_dtype=torch_dtype, variant=variant, scheduler=scheduler)\n",
    "pipe.to(device)\n",
    "\n",
    "inv_result = pipe.inverse(\n",
    "    image=image_path,\n",
    "    prompt=prompt,\n",
    "    guidance_scale=5.0,\n",
    "    num_inference_steps=num_inference_steps\n",
    ")\n",
    "\n",
    "ori_image = inv_result.ori_image\n",
    "vae_latent = image2latents(pipe, ori_image)\n",
    "vae_recon = latents2image(pipe, vae_latent)\n",
    "\n",
    "recon_image = pipe(\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    guidance_scale=5.0,\n",
    "    uncond_embeds=inv_result.uncond_embeds,\n",
    "    latents=inv_result.zT\n",
    ").images[0]\n",
    "\n",
    "del inv_result, pipe\n",
    "free_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_psnr = psnr(np.array(ori_image), np.array(vae_recon))\n",
    "vae_ssim = ssim(np.array(ori_image), np.array(vae_recon), win_size=11, channel_axis=2)\n",
    "vae_lpips = lpips_loss(pil2tensor(ori_image), pil2tensor(vae_recon)).item()\n",
    "print(f\"[VAE Reconstruction] PSNR: {vae_psnr:.2f}, SSIM: {vae_ssim:.4f}, LPIPS: {vae_lpips:.4f}\")\n",
    "\n",
    "psnr_score = psnr(np.array(ori_image), np.array(recon_image))\n",
    "ssim_score = ssim(np.array(ori_image), np.array(recon_image), win_size=11, channel_axis=2)\n",
    "lpips_score = lpips_loss(pil2tensor(ori_image), pil2tensor(recon_image)).item()\n",
    "print(f\"[DDIM Inversion] PSNR: {psnr_score:.2f}, SSIM: {ssim_score:.4f}, LPIPS: {lpips_score:.4f}\")\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "axs = fig.subplots(1, 3)\n",
    "axs[0].set_title(\"Origin\")\n",
    "axs[0].imshow(np.array(ori_image))\n",
    "axs[1].set_title(\"VAE Recon.\")\n",
    "axs[1].imshow(np.array(vae_recon))\n",
    "axs[2].set_title(\"DDIM Recon.\")\n",
    "axs[2].imshow(np.array(recon_image))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
